{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11e256a-dc85-49a6-bd64-ecf4cd8d89fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea363b0-e653-4480-9fc9-110aec36e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetUser = 's002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06abc688-cdb0-4756-8bfa-845fa913a4e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('DSL-StrongPasswordData.csv') # import the dataset\n",
    "trainSet = data.copy() # create a copy that will be used to split the test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01468029-89ce-4348-9b2a-2b6d26681ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.empty((0, 31))\n",
    "y_test = np.empty(0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfad7b4-41db-4cb9-80ab-686239c5d6c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for user in data['subject'].unique()[0:3]:\n",
    "    \n",
    "    # Select 50 random records for this user\n",
    "    user_records = trainSet[trainSet['subject'] == user].sample(n=50, random_state=42)\n",
    "    \n",
    "    #Remove record from trainSet\n",
    "    trainSet = trainSet.drop(user_records.index)\n",
    "    \n",
    "    # Append the typing data to X_test\n",
    "    X_test = np.vstack((X_test, user_records[['H.period', 'DD.period.t', 'UD.period.t', 'H.t', 'DD.t.i', 'UD.t.i', 'H.i', 'DD.i.e', 'UD.i.e', 'H.e', 'DD.e.five', 'UD.e.five', 'H.five', 'DD.five.Shift.r', 'UD.five.Shift.r', 'H.Shift.r', 'DD.Shift.r.o', 'UD.Shift.r.o', 'H.o', 'DD.o.a', 'UD.o.a', 'H.a', 'DD.a.n', 'UD.a.n', 'H.n', 'DD.n.l', 'UD.n.l', 'H.l', 'DD.l.Return', 'UD.l.Return', 'H.Return']].values))\n",
    "    \n",
    "    # Append the subject labels to y_test\n",
    "    y_test = np.hstack((y_test, np.where(user_records['subject'] == targetUser, 1, 0)))\n",
    "    \n",
    "trainSet['subject'] = np.where(trainSet['subject'] == targetUser, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2150989a-a6c0-459b-bda0-3e9579d67153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#X_test = scaler.fit_transform(X_test) # Normalising X for testSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d415ba3-e7f7-4eec-bea2-1e7ffebeff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a2e810-9cb4-4bbd-a2ea-ec3be262776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(128, input_shape=X_test.shape[1:], activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27671539-4f31-4287-8220-303cc64e2949",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa98f9e2-7096-44a1-8a8f-6c39654b63b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # metric to monitor\n",
    "    patience=10,  # number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1,  # whether to print updates to the console\n",
    "    restore_best_weights=True  # whether to restore the weights from the epoch with the best monitored metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adb19b8-2987-4d43-b54a-22b3cbfd3748",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sizes = [25, 50, 75, 100, 125, 150, 175, 200, 225, 250, 275, 300, 325, 350]\n",
    "\n",
    "roc_auc_scores = []\n",
    "roc_auc_binary_scores = []\n",
    "\n",
    "# Loop through each training data subset size and train/evaluate the model\n",
    "for size in train_sizes:\n",
    "    # Reset the model to an untrained state\n",
    "    model.reset_states()\n",
    "    \n",
    "    user_records = shuffle(trainSet[trainSet['subject'] == 1], random_state = 42)\n",
    "    non_user_records = shuffle(trainSet[trainSet['subject'] == 0], random_state = 42)\n",
    "    \n",
    "    train_user_records = user_records.groupby('subject').apply(lambda x: x.sample(size))\n",
    "    train_non_user_records = non_user_records.groupby('subject').apply(lambda x: x.sample(size))\n",
    "    \n",
    "    # Subset the training data to the specified size\n",
    "    train_data_subset = pd.concat([train_user_records, train_non_user_records])\n",
    "    \n",
    "    # Shuffle the data\n",
    "    train_data_subset = shuffle(train_data_subset, random_state = 42)\n",
    "    \n",
    "    # Split dataset into X and y\n",
    "    X_train = train_data_subset.drop(['subject', 'sessionIndex', 'rep'], axis=1).values\n",
    "    y_train = train_data_subset['subject']\n",
    "    \n",
    "    # Normalising X\n",
    "    #X_train = scaler.fit_transform(X_train) # Normalising X for trainSet\n",
    "    \n",
    "    \n",
    "    # Train the model on the subset of training data\n",
    "    model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "    \n",
    "    # Predict the test set\n",
    "    prediction = model.predict(X_test)\n",
    "    \n",
    "    # Classify the prediction results\n",
    "    prediction_binary = np.where(prediction > 0.90, 1, 0)\n",
    "    \n",
    "    # Calculate AUC based on prediction\n",
    "    # Calculate false-pos and true-pos rates\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, prediction_binary)\n",
    "    roc_auc = auc(fpr, tpr)    \n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, prediction_binary, labels=[0,1]).ravel()\n",
    "    \n",
    "    if tp + fp > 0:\n",
    "        precision = tp / (tp + fp)\n",
    "    else:\n",
    "        precision = 0\n",
    "    \n",
    "    if tp + fn > 0:\n",
    "        recall = tp / (tp + fn)\n",
    "    else:\n",
    "        recall = 0\n",
    "\n",
    "    if precision + recall > 0:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1 = 0\n",
    "    \n",
    "    # Evaluate the model on the test set and record the ROC AUC score\n",
    "    roc_auc_binary_scores.append({'Size': size, 'FPR': fpr, 'TPR': tpr, 'AUC': roc_auc, 'F1': f1, 'P': precision, 'R': recall})\n",
    "    # Calculate AUC based on prediction\n",
    "    # Calculate false-pos and true-pos rates\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, prediction)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Evaluate the model on the test set and record the ROC AUC score\n",
    "    roc_auc_scores.append({'Size': size, 'FPR': fpr, 'TPR': tpr, 'AUC': roc_auc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1182fc3-66bd-4f60-aa16-d87c43590280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in roc_auc_scores:\n",
    "    plt.plot(x['FPR'], x['TPR'], label='{} Records Per User (AUC = {:.2f})'.format(x['Size'], x['AUC']))\n",
    "\n",
    "    \n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random guessing Line')  # Random guessing line\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\", fontsize=9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c886605b-3fea-4cbe-9fa0-a0b89f8ec94e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in roc_auc_binary_scores:\n",
    "    plt.plot(x['FPR'], x['TPR'], label='{} Records Per User (AUC = {:.2f})'.format(x['Size'], x['AUC']))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random guessing Line')  # Random guessing line\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\", fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff9135-7d98-4477-8d69-fd5a14fba4cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUC = []\n",
    "Binary_AUC = []\n",
    "F1 = []\n",
    "Precision = []\n",
    "Recall = []\n",
    "\n",
    "for x in roc_auc_scores:\n",
    "    AUC.append(x['AUC'])\n",
    "    \n",
    "for x in roc_auc_binary_scores:\n",
    "    \n",
    "    Binary_AUC.append(x['AUC'])\n",
    "    F1.append(x['F1'])\n",
    "    Precision.append(x['P'])\n",
    "    Recall.append(x['R'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71d3657-55db-464c-9eff-0326880c08ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(train_sizes, Binary_AUC, label=\"Classified AUC with 0.90 Threshold\")\n",
    "plt.xlabel('Number of Records Per Class')\n",
    "plt.ylabel('AUC Value')\n",
    "plt.title('Comparison of Area under ROC Curves')\n",
    "plt.legend(loc=\"lower right\", fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbac6f66-6b28-4ef4-8934-243911430228",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(1, len(Binary_AUC)):\n",
    "    rateOfIncrease = ((Binary_AUC[x] - Binary_AUC[x-1]))\n",
    "    print(str(round(rateOfIncrease, 4)))\n",
    "    \n",
    "for x in range(0, len(Binary_AUC)):\n",
    "    print(round(Binary_AUC[x], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c04d00-6db0-47f6-aca4-550f9b785575",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(train_sizes, F1, label=\"F1 Scores with 0.75 Threshold\")\n",
    "plt.plot(train_sizes, Precision, label=\"Precision Scores with 0.75 Threshold\")\n",
    "plt.plot(train_sizes, Recall, label=\"Recall Scores with 0.75 Threshold\")\n",
    "plt.title('F1, Precision and Recall Score')\n",
    "plt.xlabel('Number of Records Per Class')\n",
    "plt.ylabel('Score')\n",
    "plt.legend(loc=\"lower right\", fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a9b8c6-0186-493e-8198-90538a8ea3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1:\", F1)\n",
    "print(\"Precision:\", Precision)\n",
    "print(\"Recall:\", Recall)\n",
    "\n",
    "print(len(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4c569e-99cf-403e-85c6-13b1987d75fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in range(1, len(F1)):\n",
    "    rateOfIncrease = (F1[x] - F1[x-1])\n",
    "    print(str(round(rateOfIncrease, 4)))\n",
    "    \n",
    "for x in range(0, len(F1)):\n",
    "    print(round(F1[x], 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
